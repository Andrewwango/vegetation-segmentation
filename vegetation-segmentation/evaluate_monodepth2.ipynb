{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exclusive-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy, csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from deeplabv3 import FreiburgTestDataset, FreiburgDepthTestDataset, cf, dn, nut, c2e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-economy",
   "metadata": {},
   "source": [
    "## Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reflected-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "private-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig_img_shape = (480,640)#(768, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_val = FreiburgTestDataset(\"data/freiburg/val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-suicide",
   "metadata": {},
   "source": [
    "## Obtain depth prediction with monodepth2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "early-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change transform to match monodepth2's required size\n",
    "fd_val.transforms = torchvision.transforms.Compose([Image.fromarray,\n",
    "                                                     lambda x: x.resize((640, 192), Image.LANCZOS), \n",
    "                                                     torchvision.transforms.ToTensor()])\n",
    "test_dataloader2 = torch.utils.data.DataLoader(fd_val, batch_size=batch_size, shuffle=False)\n",
    "test_img2 = next(iter(test_dataloader2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "white-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monodepth2 import estimate_depthmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sitting-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andre\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "test_depth_pred = estimate_depthmap(test_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iraqi-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img2 = dn(test_img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-pastor",
   "metadata": {},
   "source": [
    "fig,axs=plt.subplots(batch_size,2, figsize=(20,20))\n",
    "for i in range(2):\n",
    "    axs[i,0].imshow(c2e(test_img2[i]))\n",
    "    axs[i,1].imshow(test_depth_pred[i], cmap='gray' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-fifty",
   "metadata": {},
   "source": [
    "# Retrieve ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "colonial-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_depth_test = FreiburgDepthTestDataset(\"data/freiburg/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "later-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_depth_true = np.zeros((len(fd_depth_test), 192, 640))\n",
    "for i in range(len(fd_depth_test)):\n",
    "    test_depth_true[i] = fd_depth_test[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-biodiversity",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggregate-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prerequisite-estimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.clip(1/test_depth_pred, 0.0, 1.0)\n",
    "b = test_depth_true[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expired-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPEs = []\n",
    "for i in range(a.shape[0]):\n",
    "    MAPEs.append(mean_absolute_percentage_error(b[i].flatten(), a[i].flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "elegant-canberra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30508909889900093"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MAPEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "continent-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18173999869727103"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(b, a, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extended-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMCCs = []\n",
    "for i in range(a.shape[0]):\n",
    "    PMCCs.append(np.corrcoef(b[i].flatten(), a[i].flatten())[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "injured-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891660623451184"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(PMCCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "silent-charter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7687834946811526"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(b.flatten(), a.flatten())[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-blind",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
